https://access.redhat.com/hydra/rest/search/kcs?q=*%3A*&start=50&hl=true&hl.fl=abstract&hl.simple.pre=%253Cmark%253E&hl.simple.post=%253C%252Fmark%253E&fq=%7B%21tag%3Date%7Dportal_publication_date%3A%28%5B2024-01-01T00%3A00%3A00.000Z+TO+2024-01-01T00%3A00%3A00.000Z%2B1YEAR%5D%29+AND+documentKind%3A%28%22Errata%22%29&facet=true&facet.mincount=1&facet.range=%7B%21ex%3Date%7Dportal_publication_date&facet.range.end=NOW&facet.range.gap=%2B1YEAR&facet.range.start=NOW%2FYEAR-15YEARS&rows=1&fl=id%2Cportal_severity%2Cportal_advisory_type%2Cportal_product_names%2Cportal_publication_date%2Cportal_synopsis%2Cview_uri%2CallTitle&sort=portal_publication_date+desc&p=5&facet.field=portal_advisory_type&facet.field=portal_severity&fq=portal_product_filter%3A*%7C*

# api = f'https://access.redhat.com/hydra/rest/search/kcs?q=*%3A*&start=50&hl=true&hl.fl=abstract&hl.simple.pre=%253Cmark%253E&hl.simple.post=%253C%252Fmark%253E&fq={fq}&facet=true&facet.mincount=1&facet.range=%7B%21ex%3Date%7Dportal_publication_date&facet.range.end=NOW&facet.range.gap=%2B1YEAR&facet.range.start=NOW%2FYEAR-15YEARS&rows=1&fl=id%2Cportal_severity%2Cportal_advisory_type%2Cportal_product_names%2Cportal_publication_date%2Cportal_synopsis%2Cview_uri%2CallTitle&sort=portal_publication_date+desc&p=5&facet.field=portal_advisory_type&facet.field=portal_severity'
portal_advisory_type:('Security Advisory') AND portal_product_filter:Red\ Hat\ Enterprise\ Linux|*|*|x86_64

&fq=portal_advisory_type%3A%28%22Security+Advisory%22%29+AND+documentKind%3A%28%22Errata%22%29

    # else:
    #     scraped.append({'OS':f'OL{version}','id':aid,'Advisory link': link,'type':Type ,'Release Date': Release_Date, 'vonder rating':Severity, 'summary':summary, 'Rpms': 'None', "CVEs": Cves })
    #     log.warn(f'No Rpms found for Oracle Linux {version}')

url = f'https://linux.oracle.com/ords/f?p=105:21:3414613945235:pg_R_1213672130548773998:NO&pg_min_row=1&pg_max_rows={max_rows}&pg_rows_fetched={max_rows}'


    
RHEL  Version	Matching string

RHEL   7	    Red Hat Enterprise Linux Server 7
RHEL   8	    Red Hat Enterprise Linux for x86_64 8
RHEL   9	    Red Hat Enterprise Linux for x86_64 9
RHEL   8.2	    Red Hat Enterprise Linux for x86_64 - Update Services for SAP Solutions 8.2
RHEL   8.4	    Red Hat Enterprise Linux for x86_64 - Update Services for SAP Solutions 8.4
RHEL   8.6	    Red Hat Enterprise Linux for x86_64 - Update Services for SAP Solutions 8.6
RHEL   8.8	    Red Hat Enterprise Linux for x86_64 - Update Services for SAP Solutions 8.8



 


 def get_links(html):
    
    links = []
    soup = BeautifulSoup(html,features='html.parser') 
    table = soup.find('table',class_="report-standard-alternatingrowcolors")
    rows = table.find_all("tr",class_="highlight-row")
    for row in rows :
       links.append("https://linux.oracle.com" + row.select_one('td[headers="ADVISORY_ID"] a')['href'])
    
    return links


    def extract(links):
    rlink = 1
    data = []
    for link in links:
       print(f'Getting : {rlink}/{len(links)} row')
       data.extend(scrape(link, 7))
    #    data.extend(scrape(link, 8))
       rlink = rlink + 1    
    return data
       

    
# Oracle Linux 9 (x86_64)
           
def scrape(link, version):

    html = get_html(link) 
    soup = BeautifulSoup(html,features='html.parser')
    aid = soup.find('li',string=lambda text: text and (text.startswith('ELEA') or text.startswith('ELSA')or text.startswith('ELBA'))).text.strip()
    container = soup.find('div', class_="mc10 mc10v6")
    summary = container.find('h2').text.strip().split(' - ')[1]
    tables = container.find_all('table')
    Type = tables[0].find_all('tr')[0].find_all('td')[1].text.strip()
    Severity = tables[0].find_all('tr')[1].find_all('td')[1].text.strip()
    Release_Date = tables[0].find_all('tr')[2].find_all('td')[1].text.strip()
    Cves =  ', '.join([td.text.strip() for td in tables[1].find_all("tr")])
    category = "General Advisory" if Type == 'BUG' else "Security Advisory"
    scraped = []
    start_row = None
    
    if soup.find('td',string=f"Oracle Linux {version} (x86_64)"):
        start_row = soup.find('td',string=f"Oracle Linux {version} (x86_64)").find_parent()
        # scraped.append({'OS':f'OL{version}','id':aid,'Advisory link': link,'type':Type ,'Release Date': Release_Date, 'vonder rating':Severity, 'summary':summary, 'Rpms': start_row.find_all('td')[1].text.strip(), "CVEs": Cves })
        scraped.append({
                        'OS': f'OL{version}',
                        'Release Date': Release_Date,
                        'Category': category,
                        'Vendor Category': Type,
                        'Bulletin ID / Patch ID': aid, 
                        'RPMs': start_row.find_all('td')[1].text.strip(),
                        'CVEs':Cves ,
                        'Bulletin Title and Executive Summary':summary,
                        'Vendor Rating': Severity,
                        'Atos Rating':'N/A',
                        'Tested':'NO',
                        'Exception':'NO',
                        'Announcement links': link
            })
        
        rpms = start_row.find_all_next('tr')
        #Extract rpms from the target rows in table
        for rpm in rpms:
            rpm_elements = rpm.find_all('td')
            # rpm.find_all('td')[1].text.strip()
            if len(rpm_elements) >= 2:
                rpms_value = rpm_elements[1].text.strip()
            else:
                rpms_value = "N/A"
              
            scraped.append({
                        'OS': f'OL{version}',
                        'Release Date': Release_Date,
                        'Category': category,
                         'Vendor Category': Type,
                        'Bulletin ID / Patch ID': aid, 
                        'RPMs':str(rpms_value),
                        'CVEs':Cves ,
                        'Bulletin Title and Executive Summary':summary,
                        'Vendor Rating': Severity,
                        'Atos Rating':'N/A',
                        'Tested':'NO',
                        'Exception':'NO',
                        'Announcement links': link
            })
    return scraped
        
